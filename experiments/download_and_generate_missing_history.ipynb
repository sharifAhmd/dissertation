{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2244479d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff58272",
   "metadata": {},
   "source": [
    "## Solar cycle history\n",
    "Solar Cycle 22: October 1986 to June 1996  \n",
    "Solar Cycle 23: June 1996 to December 2008  \n",
    "Solar Cycle 24: December 2008 to December 2019  \n",
    "Solar Cycle 25: 2019 - (projected) 2030  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c17fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import json\n",
    "import shutil\n",
    "import requests\n",
    "import pandas as pd\n",
    "import urllib.request\n",
    "from typing import Tuple\n",
    "\n",
    "DATA_DIR = \"data_from_sol_22_raw\"\n",
    "missing_infos = {}\n",
    "\n",
    "def create_folder(year: int):\n",
    "    #create folder to hold the data\n",
    "    os.makedirs(f\"{DATA_DIR}/{year}\", exist_ok = True)\n",
    "\n",
    "def download_file(year: int, url: str, file_name: str) -> None:\n",
    "    # download the file from `url` and save it locally under `file_name`:\n",
    "    with urllib.request.urlopen(url) as response, open(f\"{DATA_DIR}/{year}/{file_name}\", 'wb') as out_file:\n",
    "        shutil.copyfileobj(response, out_file)\n",
    "\n",
    "def get_continuous_ranges(nums: list) -> list[Tuple]:\n",
    "    # helper function to get continuous interval\n",
    "    nums = sorted(set(nums))\n",
    "    gaps = [[s, e] for s, e in zip(nums, nums[1:]) if s+1 < e]\n",
    "    edges = iter(nums[:1] + sum(gaps, []) + nums[-1:])\n",
    "    return list(zip(edges, edges))\n",
    "    \n",
    "def get_missing_info(file_path: str, found_data_key: str) -> Tuple[list[str], list[int]]:\n",
    "    # get different missing data informations\n",
    "    list_missing_intervals = []\n",
    "    list_missing_length = []\n",
    "    \n",
    "    df = pd.read_csv(file_path)\n",
    "    if found_data_key == \"starting_point_new\":\n",
    "        col = \"A_AVG\"\n",
    "    elif found_data_key == \"starting_point_old\" or found_data_key == \"starting_point_old_v2\":\n",
    "        col = \"xl\"\n",
    "        \n",
    "    df_missing_values = df.loc[df[col] == -99999]\n",
    "    missing_indexes = df_missing_values.index.tolist()\n",
    "\n",
    "    intervals = get_continuous_ranges(missing_indexes)\n",
    "    for interval in intervals:\n",
    "        st =  df.iloc[[interval[0]]].values.tolist()[0][0]\n",
    "        end = df.iloc[[interval[1]]].values.tolist()[0][0]\n",
    "        list_missing_intervals.append(f\"{st} to {end}\")\n",
    "        list_missing_length.append(interval[1] - interval[0] + 1)\n",
    "    \n",
    "    return list_missing_intervals, list_missing_length\n",
    "\n",
    "def pre_process_data(missing_infos:dict, satelite: str, year: int, month: str, file_name: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract the important rows and save them as csv\n",
    "    Also get some information about missing values\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    yearly_missing_dict = {}\n",
    "    missing_row_counter = 0\n",
    "    \n",
    "    csv_filename_with_dir = f\"{DATA_DIR}/{year}/{file_name}\"\n",
    "    starting_point_found = False\n",
    "    found_data_key = \"\"\n",
    "    original_data_dict = {\n",
    "        \"starting_point_new\" : ['time_tag', 'A_QUAL_FLAG', 'A_NUM_PTS', 'A_AVG', 'B_QUAL_FLAG', 'B_NUM_PTS', 'B_AVG'],\n",
    "        \"starting_point_old\" : ['time_tag', 'xl', 'xs'],\n",
    "        \"starting_point_old_v2\" : ['time_tag', 'xs', 'xl'],\n",
    "    }\n",
    "    \n",
    "    with open(csv_filename_with_dir, newline='') as csvfile:\n",
    "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "        for row in reader:\n",
    "            if row == original_data_dict[\"starting_point_new\"]:\n",
    "                starting_point_found = True\n",
    "                found_data_key = \"starting_point_new\"\n",
    "                for col in original_data_dict[found_data_key]:\n",
    "                    data_dict[col] = []\n",
    "                continue\n",
    "                \n",
    "            if row == original_data_dict[\"starting_point_old\"]:\n",
    "                starting_point_found = True\n",
    "                found_data_key = \"starting_point_old\"\n",
    "                for col in original_data_dict[found_data_key]:\n",
    "                    data_dict[col] = []\n",
    "                continue\n",
    "            if row == original_data_dict[\"starting_point_old_v2\"]:\n",
    "                starting_point_found = True\n",
    "                found_data_key = \"starting_point_old_v2\"\n",
    "                for col in original_data_dict[found_data_key]:\n",
    "                    data_dict[col] = []\n",
    "                continue\n",
    "                \n",
    "            if starting_point_found:\n",
    "                for i, col in enumerate(original_data_dict[found_data_key]):\n",
    "                    data_dict[col].append(row[i])\n",
    "\n",
    "    df = pd.DataFrame.from_dict(data_dict)\n",
    "    df.to_csv(csv_filename_with_dir, index = False)\n",
    "    \n",
    "    yearly_missing_dict[\"file_name\"] = f\"{year}/{file_name}\"\n",
    "    yearly_missing_dict[\"number of total rows\"] = df.shape[0]\n",
    "    list_missing_intervals, list_missing_length = get_missing_info(csv_filename_with_dir, found_data_key)\n",
    "    yearly_missing_dict[\"number of missing rows\"] = sum(list_missing_length)\n",
    "    yearly_missing_dict[\"missing rows each interval\"] = list_missing_length\n",
    "    yearly_missing_dict[\"missing intervals\"] = list_missing_intervals\n",
    "    missing_infos[f\"{satelite}_{month}\"] = yearly_missing_dict\n",
    "    \n",
    "    return missing_infos\n",
    "    \n",
    "def download_data_by_year():\n",
    "    \"\"\"\n",
    "    Need some steps to get the data from www.ncei.noaa.gov\n",
    "        -> Need date range of the year by month\n",
    "        -> Need the filename\n",
    "        -> Need the URL for file in NOAA website\n",
    "        -> Download the data\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(\"existing_data_history.csv\")\n",
    "    years = [year for year in range(1986, 2021)]\n",
    "    \n",
    "    for year in years:\n",
    "        print(f\"Downloading data for {year}\")\n",
    "        missing_infos = {}\n",
    "        #create folder to hold data\n",
    "        create_folder(year)\n",
    "        \n",
    "        filtered_df = df[df[\"year\"] == year]\n",
    "        rows_as_list = filtered_df.values.tolist()\n",
    "        for row in rows_as_list:\n",
    "            satelite, year, month, file_name, url = row\n",
    "            month = f\"{month:02d}\"\n",
    "            download_file(year, url, file_name)\n",
    "            print(f\"Download completed of {file_name}, url: {url}\")\n",
    "            \n",
    "            missing_infos = pre_process_data(missing_infos, satelite, year, month, file_name)\n",
    "            print(f\"Pre-processing completed of {file_name}\")\n",
    "            print(\"......\")\n",
    "    \n",
    "        print(f\"saving summary for year {year}\")\n",
    "        with open(f\"{DATA_DIR}/{year}_summary.json\", \"w\") as fp:\n",
    "            json.dump(missing_infos, fp)\n",
    "        \n",
    "        print(f\"--------End of {year}--------\")\n",
    "\n",
    "download_data_by_year()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
