{"cells":[{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:41:35.801420Z","iopub.status.busy":"2024-02-11T02:41:35.801057Z","iopub.status.idle":"2024-02-11T02:41:38.614749Z","shell.execute_reply":"2024-02-11T02:41:38.613565Z","shell.execute_reply.started":"2024-02-11T02:41:35.801390Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import warnings\n","warnings.filterwarnings('ignore')\n","from itertools import cycle\n","import datetime as dt\n","from torch.autograd import Variable\n","import random \n","import os\n","from matplotlib.pyplot import figure\n","import torch\n","import torch.nn as nn\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import MinMaxScaler\n","import time \n","import torch.nn.functional as F\n","import warnings\n","from fastprogress.fastprogress import master_bar, progress_bar\n","import torch.nn as nn\n","import torch.optim as optim\n","from copy import deepcopy\n","%matplotlib inline\n","\n","warnings.filterwarnings(\"ignore\")\n","plt.style.use('bmh')\n","color_pal = plt.rcParams['axes.prop_cycle'].by_key()['color']\n","color_cycle = cycle(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n","\n"," "]},{"cell_type":"markdown","metadata":{},"source":["## Set device parameters"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:41:38.617155Z","iopub.status.busy":"2024-02-11T02:41:38.616876Z","iopub.status.idle":"2024-02-11T02:41:38.643548Z","shell.execute_reply":"2024-02-11T02:41:38.642601Z","shell.execute_reply.started":"2024-02-11T02:41:38.617128Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["device is: cuda\n"]}],"source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","print(\"device is:\",device)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["fill_type = \"mean\"\n","seq_length = 120\n","labels_length = 30"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["df_train = pd.read_csv(f\"advance_work/{fill_type}/train.csv\")\n","df_val = pd.read_csv(f\"advance_work/{fill_type}/val.csv\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["def meets_threshold(value, threshold=1e-5):\n","    return value >= threshold\n","\n","# Function to build the dataset\n","def build_dataset(df):\n","    X, Y = [], []\n","    xl_col = df['xl'].values  \n","    for i in range(len(xl_col) - (seq_length + labels_length)):\n","        if meets_threshold(xl_col[i + seq_length]):\n","            x_ = xl_col[i:i + seq_length].tolist()\n","            x_ = [[-np.log(v)] for v in x_]\n","            X.append(np.array(x_))\n","            y_ = xl_col[i + seq_length:i + seq_length + labels_length].tolist()\n","            y_ = [[-np.log(v)] for v in y_]\n","            Y.append(np.array(y_))\n","    \n","    return X, Y"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["train_X, train_y = build_dataset(df_train)\n","valid_X, valid_y = build_dataset(df_val)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["4"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","del df_test, df_train, df_val\n","gc.collect()"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:42:31.866500Z","iopub.status.busy":"2024-02-11T02:42:31.866140Z","iopub.status.idle":"2024-02-11T02:42:32.194099Z","shell.execute_reply":"2024-02-11T02:42:32.192419Z","shell.execute_reply.started":"2024-02-11T02:42:31.866468Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["trainX shape is: torch.Size([191767, 120, 1])\n","trainy shape is: torch.Size([191767, 30, 1])\n","validX shape is: torch.Size([31875, 120, 1])\n","validy shape is: torch.Size([31875, 30, 1])\n"]}],"source":["\n","trainX = Variable(torch.Tensor(train_X))\n","trainy = Variable(torch.Tensor(train_y))\n","\n","validX = Variable(torch.Tensor(valid_X))\n","validy= Variable(torch.Tensor(valid_y))\n","\n","print (\"trainX shape is:\",trainX.size())\n","print (\"trainy shape is:\",trainy.size())\n","print (\"validX shape is:\",validX.size())\n","print (\"validy shape is:\",validy.size())"]},{"cell_type":"markdown","metadata":{},"source":["### Summery of the dataset used for all the experiments\n","```\n","trainX shape is: torch.Size([58024, 120, 1])\n","trainy shape is: torch.Size([58024, 30, 1])\n","validX shape is: torch.Size([10802, 120, 1])\n","validy shape is: torch.Size([10802, 30, 1])\n","```\n","```\n","min method\n","trainX shape is: torch.Size([191767, 120, 1])\n","trainy shape is: torch.Size([191767, 30, 1])\n","validX shape is: torch.Size([31875, 120, 1])\n","validy shape is: torch.Size([31875, 30, 1])\n","```\n","\n","```\n","mean method\n","trainX shape is: torch.Size([191767, 120, 1])\n","trainy shape is: torch.Size([191767, 30, 1])\n","validX shape is: torch.Size([31875, 120, 1])\n","validy shape is: torch.Size([31875, 30, 1])\n","```\n","\n","```\n","max method\n","trainX shape is: torch.Size([392794, 120, 1])\n","trainy shape is: torch.Size([392794, 30, 1])\n","validX shape is: torch.Size([253918, 120, 1])\n","validy shape is: torch.Size([253918, 30, 1])\n","```\n","-------------------------------------------------\n","Test set\n","```\n","TestX shape is: torch.Size([13954, 120, 1])\n","Testy shape is: torch.Size([13954, 30, 1])\n","```"]},{"cell_type":"markdown","metadata":{},"source":["# Building the Seq2Seq Model <a id=\"5\"></a>"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","from torch.autograd import Variable\n","\n","class Encoder(nn.Module):\n","    \"\"\"\n","    Encoder for the Seq2Seq model\n","    \"\"\"\n","    def __init__(self, seq_len, n_features, embedding_dim=32):\n","        super(Encoder, self).__init__()\n","        self.seq_len, self.n_features = seq_len, n_features\n","        self.embedding_dim, self.hidden_dim = embedding_dim, 16  # Set hidden_dim to 16\n","        self.num_layers = 1\n","        self.lstm = nn.LSTM(\n","            input_size=n_features,\n","            hidden_size=self.hidden_dim,\n","            num_layers=1,\n","            batch_first=True,\n","            dropout=0.35\n","        )\n","   \n","    def forward(self, x):\n","        device = x.device\n","        x = x.reshape((1, self.seq_len, self.n_features))\n","        h_1 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device))\n","        c_1 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_dim).to(device))\n","        x, (hidden, cell) = self.lstm(x, (h_1, c_1))\n","        return x, hidden, cell\n","\n","class Decoder(nn.Module):\n","    \"\"\"\n","    Decoder for the Seq2Seq model\n","    \"\"\"\n","    def __init__(self, seq_len, input_dim=32, n_features=1):\n","        super(Decoder, self).__init__()\n","        self.seq_len, self.input_dim = seq_len, input_dim\n","        self.hidden_dim, self.n_features = 16, n_features \n","        self.lstm = nn.LSTM(\n","            input_size=1,\n","            hidden_size=16,  \n","            num_layers=1,\n","            batch_first=True,\n","            dropout=0.35\n","        )\n","        self.output_layer = nn.Linear(self.hidden_dim, n_features)\n","\n","    def forward(self, x, input_hidden, input_cell):\n","        device = x.device\n","        x = x.reshape((1, 1, 1))\n","        x, (hidden_n, cell_n) = self.lstm(x, (input_hidden, input_cell))\n","        x = self.output_layer(x)\n","        return x, hidden_n, cell_n\n","\n","class Seq2Seq(nn.Module):\n","    \"\"\"\n","    Seq2Seq model\n","    \"\"\"\n","    def __init__(self, seq_len, n_features, embedding_dim=32, output_length=labels_length):\n","        super(Seq2Seq, self).__init__()\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        self.encoder = Encoder(seq_len, n_features, embedding_dim).to(device)\n","        self.output_length = output_length\n","        self.decoder = Decoder(seq_len, embedding_dim, n_features).to(device)\n","\n","    def forward(self, x, prev_y):\n","        encoder_output, hidden, cell = self.encoder(x)\n","        targets_ta = []\n","        prev_output = prev_y\n","        for out_days in range(self.output_length):\n","            prev_x, prev_hidden, prev_cell = self.decoder(prev_output, hidden, cell)\n","            hidden, cell = prev_hidden, prev_cell\n","            prev_output = prev_x\n","            targets_ta.append(prev_x.reshape(1))\n","        targets = torch.stack(targets_ta)\n","        return targets\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:42:53.187971Z","iopub.status.busy":"2024-02-11T02:42:53.187578Z","iopub.status.idle":"2024-02-11T02:42:57.214847Z","shell.execute_reply":"2024-02-11T02:42:57.213980Z","shell.execute_reply.started":"2024-02-11T02:42:53.187937Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (lstm): LSTM(1, 16, batch_first=True, dropout=0.35)\n","  )\n","  (decoder): Decoder(\n","    (lstm): LSTM(1, 16, batch_first=True, dropout=0.35)\n","    (output_layer): Linear(in_features=16, out_features=1, bias=True)\n","  )\n",")"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["n_features = 1\n","model = Seq2Seq(seq_length, n_features)\n","model = model.to(device)\n","model"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:42:57.225931Z","iopub.status.busy":"2024-02-11T02:42:57.225603Z","iopub.status.idle":"2024-02-11T02:42:57.242773Z","shell.execute_reply":"2024-02-11T02:42:57.241694Z","shell.execute_reply.started":"2024-02-11T02:42:57.225891Z"},"trusted":true},"outputs":[{"data":{"text/plain":["Seq2Seq(\n","  (encoder): Encoder(\n","    (lstm): LSTM(1, 16, batch_first=True, dropout=0.35)\n","  )\n","  (decoder): Decoder(\n","    (lstm): LSTM(1, 16, batch_first=True, dropout=0.35)\n","    (output_layer): Linear(in_features=16, out_features=1, bias=True)\n","  )\n",")"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.uniform_(param.data, -0.08, 0.08)\n","\n","model.apply(init_weights)"]},{"cell_type":"markdown","metadata":{},"source":["#### Hyper-parameters and other settings"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:43:00.967051Z","iopub.status.busy":"2024-02-11T02:43:00.966685Z","iopub.status.idle":"2024-02-11T02:43:00.973831Z","shell.execute_reply":"2024-02-11T02:43:00.972702Z","shell.execute_reply.started":"2024-02-11T02:43:00.967021Z"},"trusted":true},"outputs":[],"source":["optimizer = torch.optim.Adam(model.parameters(), lr=4e-3,weight_decay=1e-5)\n","criterion = torch.nn.MSELoss().to(device) \n","scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 5e-3, eta_min=1e-8, last_epoch=-1)\n","#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,  patience=10, factor =0.5 ,min_lr=1e-7, eps=1e-08)"]},{"cell_type":"markdown","metadata":{},"source":["#### Training loop"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["def train_model(model, TrainX, Trainy, ValidX, Validy, seq_length, n_epochs):\n","    history = dict(train=[], val=[])\n","    best_loss = 10000.0\n","    epochs_no_improve = 0\n","    early_stop_threshold = 5  # Stop if no improvement in validation loss for 5 consecutive epochs\n","    best_model_wts = deepcopy(model.state_dict())  # Deep copy the model's state_dict\n","\n","    mb = master_bar(range(1, n_epochs + 1))\n","\n","    for epoch in mb:\n","        print(epoch, dt.datetime.now())\n","        model.train()  # Set model to training mode\n","\n","        train_losses = []\n","        for i in progress_bar(range(TrainX.size()[0]), parent=mb):\n","            seq_inp = TrainX[i, :, :].to(device)\n","            seq_true = Trainy[i, :, :].to(device)\n","\n","            optimizer.zero_grad()\n","            seq_pred = model(seq_inp.unsqueeze(0), seq_inp[seq_length-1:seq_length, :].unsqueeze(0))\n","            loss = criterion(seq_pred.squeeze(0), seq_true)\n","\n","            loss.backward()\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","            optimizer.step()\n","\n","            train_losses.append(loss.item())\n","\n","        # Validation phase\n","        val_losses = []\n","        model.eval()  # Set model to evaluation mode\n","        with torch.no_grad():\n","            for i in progress_bar(range(ValidX.size()[0]), parent=mb):\n","                seq_inp = ValidX[i, :, :].to(device)\n","                seq_true = Validy[i, :, :].to(device)\n","\n","                seq_pred = model(seq_inp.unsqueeze(0), seq_inp[seq_length-1:seq_length, :].unsqueeze(0))\n","                loss = criterion(seq_pred.squeeze(0), seq_true)\n","                val_losses.append(loss.item())\n","\n","        train_loss = np.mean(train_losses)\n","        val_loss = np.mean(val_losses)\n","\n","        history['train'].append(train_loss)\n","        history['val'].append(val_loss)\n","\n","        if val_loss < best_loss:\n","            best_loss = val_loss\n","            best_model_wts = deepcopy(model.state_dict())\n","            epochs_no_improve = 0  # Reset counter\n","            torch.save(model.state_dict(), f\"best_model_{fill_type}_seq_{seq_length}_label_{labels_length}.pt\")\n","            print(\"Saved best model at epoch:\", epoch, \"with val loss:\", val_loss)\n","        else:\n","            epochs_no_improve += 1\n","\n","        print(f'Epoch {epoch}: train loss {train_loss} val loss {val_loss}')\n","        scheduler.step()\n","\n","        if epochs_no_improve >= early_stop_threshold:\n","            print(\"Early stopping triggered\")\n","            break\n","\n","    model.load_state_dict(best_model_wts)  # Load the best model weights\n","    return model.eval(), history"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-11T02:43:08.908919Z","iopub.status.busy":"2024-02-11T02:43:08.908540Z","iopub.status.idle":"2024-02-11T02:50:03.826059Z","shell.execute_reply":"2024-02-11T02:50:03.825216Z","shell.execute_reply.started":"2024-02-11T02:43:08.908883Z"},"trusted":true},"outputs":[{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='10' class='' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      10.00% [10/100 8:35:41&lt;77:21:12]\n","    </div>\n","    \n","\n","\n","    <div>\n","      <progress value='31875' class='' max='31875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [31875/31875 02:35&lt;00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["1 2024-02-14 03:23:06.167417\n","Saved best model at epoch: 1 with val loss: 2.2829366452566404\n","Epoch 1: train loss 0.6022317319466128 val loss 2.2829366452566404\n","2 2024-02-14 04:19:33.143370\n","Saved best model at epoch: 2 with val loss: 1.204550441638676\n","Epoch 2: train loss 0.5791567322898116 val loss 1.204550441638676\n","3 2024-02-14 05:10:25.538376\n","Epoch 3: train loss 0.5754673193211568 val loss 1.2572883906289807\n","4 2024-02-14 06:01:19.707102\n","Saved best model at epoch: 4 with val loss: 1.0530952712864268\n","Epoch 4: train loss 0.5752455430415572 val loss 1.0530952712864268\n","5 2024-02-14 06:52:11.696724\n","Epoch 5: train loss 0.5697756685795625 val loss 1.6135796598918224\n","6 2024-02-14 07:43:06.294384\n","Saved best model at epoch: 6 with val loss: 1.009132662061821\n","Epoch 6: train loss 0.5885446973673445 val loss 1.009132662061821\n","7 2024-02-14 08:34:01.355040\n","Epoch 7: train loss 0.5831711863411165 val loss 1.1534799064719647\n","8 2024-02-14 09:24:53.784449\n","Epoch 8: train loss 0.5849430398428584 val loss 1.2707864956456145\n","9 2024-02-14 10:15:45.467879\n","Epoch 9: train loss 0.5817542464236117 val loss 1.0640821795342295\n","10 2024-02-14 11:06:38.887240\n","Epoch 10: train loss 0.582036368682631 val loss 1.3895426979068448\n","11 2024-02-14 11:58:47.590916\n","Epoch 11: train loss 0.5827092524128545 val loss 1.369213809504287\n","Early stopping triggered\n"]}],"source":["model, history = train_model(\n","  model,\n","  trainX,trainy,\n","  validX,validy,\n","  seq_length,\n","  n_epochs=100, \n",")"]},{"cell_type":"markdown","metadata":{},"source":["## Test Results"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["## Prepare the test dataset\n","fill_type = \"fractal\"\n","df_test = pd.read_csv(f\"advance_work/{fill_type}/test.csv\")\n","test_X, test_y = build_dataset(df_test)\n","test_X = Variable(torch.Tensor(test_X))\n","test_y = Variable(torch.Tensor(test_y))"]},{"cell_type":"markdown","metadata":{},"source":["#### Test results with fractal imputation"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='13954' class='' max='13954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [13954/13954 01:10&lt;00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["1.8678501524936588\n"]}],"source":["fill_type = \"fractal\"\n","model.load_state_dict(torch.load(f\"best_model_{fill_type}_seq_{seq_length}_label_{labels_length}.pt\"))\n","model = model.eval()\n","test_losses = []\n","with torch.no_grad():\n","    for i in progress_bar(range(test_X.size()[0])):\n","        seq_inp = test_X[i,:,:].to(device)\n","        seq_true = test_y[i,:,:].to(device)\n","\n","        seq_pred = model(seq_inp,seq_inp[seq_length-1:seq_length,:])\n","        \n","\n","        loss = criterion(seq_pred, seq_true)\n","        test_losses.append(loss.item())\n","\n","val_loss = np.mean(test_losses)\n","print(val_loss)"]},{"cell_type":"markdown","metadata":{},"source":["#### Test results with min imputation"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='5' class='' max='13954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      0.04% [5/13954 00:00&lt;01:36]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0.9625936843656333\n"]}],"source":["fill_type = \"min\"\n","\n","model.load_state_dict(torch.load(f\"best_model_{fill_type}_seq_{seq_length}_label_{labels_length}.pt\"))\n","model = model.eval()\n","test_losses = []\n","with torch.no_grad():\n","    for i in progress_bar(range(test_X.size()[0])):\n","        seq_inp = test_X[i,:,:].to(device)\n","        seq_true = test_y[i,:,:].to(device)\n","\n","        seq_pred = model(seq_inp,seq_inp[seq_length-1:seq_length,:])\n","        \n","\n","        loss = criterion(seq_pred, seq_true)\n","        test_losses.append(loss.item())\n","\n","val_loss = np.mean(test_losses)\n","print(val_loss)"]},{"cell_type":"markdown","metadata":{},"source":["#### Test results with mean imputation"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='13954' class='' max='13954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [13954/13954 01:08&lt;00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["0.6606694676633204\n"]}],"source":["fill_type = \"mean\"\n","\n","model.load_state_dict(torch.load(f\"best_model_{fill_type}_seq_{seq_length}_label_{labels_length}.pt\"))\n","model = model.eval()\n","test_losses = []\n","with torch.no_grad():\n","    for i in progress_bar(range(test_X.size()[0])):\n","        seq_inp = test_X[i,:,:].to(device)\n","        seq_true = test_y[i,:,:].to(device)\n","\n","        seq_pred = model(seq_inp,seq_inp[seq_length-1:seq_length,:])\n","        \n","\n","        loss = criterion(seq_pred, seq_true)\n","        test_losses.append(loss.item())\n","\n","val_loss = np.mean(test_losses)\n","print(val_loss)"]},{"cell_type":"markdown","metadata":{},"source":["#### Test results with max imputation"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["\n","<style>\n","    /* Turns off some styling */\n","    progress {\n","        /* gets rid of default border in Firefox and Opera. */\n","        border: none;\n","        /* Needs to be in here for Safari polyfill so background images work as expected. */\n","        background-size: auto;\n","    }\n","    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n","        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n","    }\n","    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n","        background: #F44336;\n","    }\n","</style>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["\n","    <div>\n","      <progress value='13954' class='' max='13954' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      100.00% [13954/13954 01:17&lt;00:00]\n","    </div>\n","    "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["30.367870760558585\n"]}],"source":["fill_type = \"max\"\n","\n","model.load_state_dict(torch.load(f\"best_model_{fill_type}_seq_{seq_length}_label_{labels_length}.pt\"))\n","model = model.eval()\n","test_losses = []\n","with torch.no_grad():\n","    for i in progress_bar(range(test_X.size()[0])):\n","        seq_inp = test_X[i,:,:].to(device)\n","        seq_true = test_y[i,:,:].to(device)\n","\n","        seq_pred = model(seq_inp,seq_inp[seq_length-1:seq_length,:])\n","        \n","\n","        loss = criterion(seq_pred, seq_true)\n","        test_losses.append(loss.item())\n","\n","val_loss = np.mean(test_losses)\n","print(val_loss)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":1236839,"sourceId":18599,"sourceType":"competition"},{"datasetId":672318,"sourceId":1183064,"sourceType":"datasetVersion"}],"dockerImageVersionId":29928,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}
